<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Dive into Bayesian statistics (3): Markov Chain Monte Carlo - Taotao Tan</title><meta name="Description" content="Taotao&#39;s Blog Posts"><meta property="og:title" content="Dive into Bayesian statistics (3): Markov Chain Monte Carlo" />
<meta property="og:description" content="In this post, I will continue to use the same example that I used before (Bayesian: MAP and Bayesian: solve denominator). Also, it will be very helpful to first understand accept-reject sampling that I discussed in this post.
 Now let&rsquo;s get started!
As we discussed at the end of this post, solving the denominator is a non-trivial work, especially when you have many parameters to estimate. One way to overcome this obstacle is to use a method called Markov Chain Monte Carlo (MCMC)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jasontan-code.github.io/posts/bayesian-3/" />
<meta property="og:image" content="https://jasontan-code.github.io/images/avatar.png"/>
<meta property="article:published_time" content="2021-11-22T19:18:26-06:00" />
<meta property="article:modified_time" content="2021-11-22T19:18:26-06:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jasontan-code.github.io/images/avatar.png"/>

<meta name="twitter:title" content="Dive into Bayesian statistics (3): Markov Chain Monte Carlo"/>
<meta name="twitter:description" content="In this post, I will continue to use the same example that I used before (Bayesian: MAP and Bayesian: solve denominator). Also, it will be very helpful to first understand accept-reject sampling that I discussed in this post.
 Now let&rsquo;s get started!
As we discussed at the end of this post, solving the denominator is a non-trivial work, especially when you have many parameters to estimate. One way to overcome this obstacle is to use a method called Markov Chain Monte Carlo (MCMC)."/>
<meta name="application-name" content="Taotao&#39;s Blog Posts">
<meta name="apple-mobile-web-app-title" content="Taotao&#39;s Blog Posts"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://jasontan-code.github.io/posts/bayesian-3/" /><link rel="prev" href="https://jasontan-code.github.io/posts/bayesian-2/" /><link rel="next" href="https://jasontan-code.github.io/posts/bayesian-4/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Dive into Bayesian statistics (3): Markov Chain Monte Carlo",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/jasontan-code.github.io\/posts\/bayesian-3\/"
        },"genre": "posts","keywords": "Statistics","wordcount":  831 ,
        "url": "https:\/\/jasontan-code.github.io\/posts\/bayesian-3\/","datePublished": "2021-11-22T19:18:26-06:00","dateModified": "2021-11-22T19:18:26-06:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Taotao"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Taotao Tan">Taotao Tan</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Taotao Tan">Taotao Tan</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Dive into Bayesian statistics (3): Markov Chain Monte Carlo</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Taotao</a></span>&nbsp;<span class="post-category">included in <a href="/categories/statistics/"><i class="far fa-folder fa-fw"></i>Statistics</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-22">2021-11-22</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;831 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;4 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#metropolis-algorithm">Metropolis algorithm</a></li>
    <li><a href="#r-code-implementation">R code implementation</a></li>
    <li><a href="#summary">Summary:</a>
      <ul>
        <li><a href="#reference">Reference:</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>In this post, I will continue to use the same example that I used before (<a href="https://jasontan-code.github.io/posts/bayesian-1/" target="_blank" rel="noopener noreffer">Bayesian: MAP</a> and <a href="https://jasontan-code.github.io/posts/bayesian-2/" target="_blank" rel="noopener noreffer">Bayesian: solve denominator</a>). Also, it will be very helpful to first understand accept-reject sampling that I discussed in <a href="https://jasontan-code.github.io/posts/monte_corlo/" target="_blank" rel="noopener noreffer">this post</a>.</p>
<p> <br>
 <br>
 </p>
<p>Now let&rsquo;s get started!</p>
<p>As we discussed at the end of <a href="https://jasontan-code.github.io/posts/bayesian-2/" target="_blank" rel="noopener noreffer">this post</a>, solving the denominator is a non-trivial work, especially when you have many parameters to estimate. One way to overcome this obstacle is to use a method called Markov Chain Monte Carlo (MCMC).</p>
<p><strong>The high level idea of MCMC is that although calculating the denominator is often unfeasible, we can still draw samples from the target distribution, even though we do not know the denominator (similar to the idea of accept reject sampling we discussed <a href="https://jasontan-code.github.io/posts/monte_corlo/" target="_blank" rel="noopener noreffer">here</a>).</strong></p>
<p>In this post, I will introduce a popular method of MCMC called Metropolis-Hastings algorithm. The goal of this post is to show you the steps of Metropolis-Hastings algorithm, and to implement the algorithm in R. I won&rsquo;t discuss the mathematical proof of why this algorithm works (because I do not understand neither), but show you the algorithm step by step.</p>
<p> <br>
 <br>
 </p>
<h2 id="metropolis-algorithm">Metropolis algorithm</h2>
<blockquote>
<p><strong>Step1:</strong>  Choose a distribution that is easy to sample from. Here we choose a normal distribution (set $\sigma = 1$).</p>
</blockquote>
<blockquote>
<p><strong>Step2:</strong>  Draw a sample $x_i$ form the normal distribution with $\mu = x_{i -1}, \sigma = 1$. Let&rsquo;s call this sample &ldquo;proposed sample&rdquo;</p>
</blockquote>
<blockquote>
<p><strong>Step3:</strong>   Calculate the probability of acceptance $p = \frac{f(x_i)}{f(x_{i - 1})}$, where $f(x)$ is the target distribution (without knowing the denominator).</p>
</blockquote>
<blockquote>
<p><strong>Step4:</strong> If $p &gt; 1$, simply accept the proposed distribution.</p>
</blockquote>
<blockquote>
<p><strong>Step5:</strong></p>
<ul>
<li>
<p><strong>Step5.1:</strong>  If $p &lt; 1$, flip an unfair coin with probability of heads to be $p$</p>
</li>
<li>
<p><strong>Step5.2:</strong> If we get a head from the coin, we accept the proposed sample.</p>
</li>
<li>
<p><strong>Step5.3:</strong> If we get a tail from the coin, we reject the proposed sample, but we duplicate the last accepted sample</p>
</li>
</ul>
</blockquote>
<blockquote>
<p><strong>Step6:</strong>  Repeat this process many many times.</p>
</blockquote>
<p> <br>
 <br>
 </p>
<h2 id="r-code-implementation">R code implementation</h2>
<p>If you are like me, reading all those words might not make any sense. So let&rsquo;s take a look the implementation. Again we will use the posterior distribution we calculated <a href="https://jasontan-code.github.io/posts/bayesian-1/" target="_blank" rel="noopener noreffer">here</a>:</p>
<p>$$
P(\lambda | \text{data}) = c \cdot \lambda^{19} e^{- 6 \lambda} \quad \text{, where $c$ is a constant.}
$$</p>
<p>First, we need to express the posterior in R code. Notice when $\lambda &lt; 0$, we explicitly set $f(\lambda) = 0$. Also, we ignored the constant $c$ in our expressions.</p>
<p><strong>Again, this is our target distribution $f(x)$, and the goal is to draw samples from this distribution</strong></p>
<p> </p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># define the posterior distribution</span>
<span class="n">posterior</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">lambda</span><span class="p">){</span>
  <span class="nf">if </span><span class="p">(</span><span class="n">lambda</span> <span class="o">&gt;</span> <span class="m">0</span><span class="p">){</span>
    <span class="nf">return</span><span class="p">(</span><span class="n">lambda^19</span> <span class="o">*</span> <span class="nf">exp</span><span class="p">(</span><span class="m">-6</span><span class="o">*</span><span class="n">lambda</span><span class="p">))</span>
  <span class="p">}</span> <span class="n">else</span> <span class="p">{</span>
    <span class="nf">return</span><span class="p">(</span><span class="m">0</span><span class="p">)</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p> <br>
 </p>
<p>Now let&rsquo;s implement the Metropolis algorithm. Notice I use a vector called <code>bag</code> to collect all the samples:</p>
<p> </p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># we need a place to start with, I set 8</span>
<span class="n">bag</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">8</span><span class="p">)</span>

<span class="c1"># Metropolis algorithm</span>
<span class="nf">for</span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">2</span><span class="o">:</span><span class="m">5000</span><span class="p">){</span>
  <span class="n">proposed</span> <span class="o">=</span> <span class="nf">rnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span> <span class="n">bag[i</span><span class="m">-1</span><span class="n">]</span><span class="p">)</span>    <span class="c1"># propose a sample from the standard distribution</span>
  <span class="n">prob</span> <span class="o">=</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">proposed</span><span class="p">)</span><span class="o">/</span><span class="nf">posterior</span><span class="p">(</span><span class="n">bag[i</span><span class="m">-1</span><span class="n">]</span><span class="p">)</span>    <span class="c1"># calculate the probability of acceptance </span>
  
  <span class="nf">if </span><span class="p">(</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="m">1</span><span class="p">){</span>
    <span class="n">bag[i]</span> <span class="o">=</span> <span class="n">proposed</span>     <span class="c1"># if probability is greater than 1, we accept the proposed sample</span>
  <span class="p">}</span> <span class="n">else</span> <span class="p">{</span>
    <span class="n">coin</span> <span class="o">=</span> <span class="nf">rbinom</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span><span class="p">)</span>  <span class="c1"># flip an unfair coin  </span>
    <span class="nf">if </span><span class="p">(</span><span class="n">coin</span> <span class="o">==</span> <span class="m">1</span><span class="p">){</span>
      <span class="n">bag[i]</span> <span class="o">=</span> <span class="n">proposed</span>    <span class="c1"># if the coin turned out to be head, we accept the proposed sample</span>
    <span class="p">}</span> <span class="n">else</span> <span class="p">{</span>
      <span class="n">bag[i]</span> <span class="o">=</span> <span class="n">bag[i</span><span class="m">-1</span><span class="n">]</span>    <span class="c1"># if the coin turned out to be tail, we duplicated the last accepted sample</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p> <br>
 </p>
<p>Here is what the result looks like.</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/Bayesian3/MCMC.png"
        data-srcset="/images/Bayesian3/MCMC.png, /images/Bayesian3/MCMC.png 1.5x, /images/Bayesian3/MCMC.png 2x"
        data-sizes="auto"
        alt="/images/Bayesian3/MCMC.png"
        title="bayesian3" /></p>
<p>On the right hand side plot, we simply connect all the dots in the vector <code>bag</code>. I used ggplot to draw this, but you can also draw this with <code>plot(accept, &quot;l&quot;)</code>.</p>
<p>Notice at the very beginning, our samples have large values (6~8), but then it drops to a smaller value and stay relatively stable. The samples we collected at the beginning is called &ldquo;burn in period&rdquo;, which means the Markov Chain hasn&rsquo;t reached to a steady state, and these samples aren&rsquo;t representative and should be discarded.</p>
<p> <br>
On the left hand side plot, I threw away the first 200 &ldquo;burn in&rdquo; samples, and drew a density histogram for the rest of my samples (you can draw this by tying   <code>hist(accept[201:5000])</code>). The red line is the density line from our data. The green line is the theoretical probability density function of $\text{Gamma}(\alpha = 20, \beta = 6)$.</p>
<p>You can see the density line is very similar to our ground truth (the green line, which we have calculated <a href="https://jasontan-code.github.io/blog/bayesian-2/" target="_blank" rel="noopener noreffer">here</a>), which proves that our Metropolis algorithm indeed works.</p>
<p> <br>
 </p>
<h2 id="summary">Summary:</h2>
<p>In this series of posts, we started from Maximum likelihood estimation, then incorporate a Gamma prior distribution and use various methods (integration, conjugate prior, and MCMC) to infer the posterior distribution. I hope this series of posts really helps you step into the door of Bayesian inference. If you like this post, simply drop a thumb up, and leave some comments.</p>
<p> <br>
 
 </p>
<h3 id="reference">Reference:</h3>
<p>ritvikmath: <a href="https://www.youtube.com/watch?v=yApmR-c_hKU">https://www.youtube.com/watch?v=yApmR-c_hKU</a></p>
<p>ritvikmath: <a href="https://www.youtube.com/watch?v=yCv2N7wGDCw">https://www.youtube.com/watch?v=yCv2N7wGDCw</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-22</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo" data-via="doubleTaoTan" data-hashtags="Statistics"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-hashtag="Statistics"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Myspace" data-sharer="myspace" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo" data-description=""><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo" data-description=""><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="https://jasontan-code.github.io/posts/bayesian-3/" data-title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/statistics/">Statistics</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/bayesian-2/" class="prev" rel="prev" title="Dive into Bayesian statistics (2): Solve the nasty denominator!"><i class="fas fa-angle-left fa-fw"></i>Dive into Bayesian statistics (2): Solve the nasty denominator!</a>
            <a href="/posts/bayesian-4/" class="next" rel="next" title="Dive into Bayesian statistics (4): Posterior predictive distribution">Dive into Bayesian statistics (4): Posterior predictive distribution<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="fb-root" class="comment"></div>
            <div
                class="fb-comments"
                data-href="https://jasontan-code.github.io/posts/bayesian-3/"
                data-width="100%"
                data-numposts="10"
            ></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://developers.facebook.com/docs/plugins/comments/"></a>Facebook</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.80.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v5.0&amp;appId=2162149760591137&amp;autoLogAppEvents=1" defer></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-C4MZRQHWVE', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=G-C4MZRQHWVE" async></script></body>
</html>
