<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Dive into Bayesian statistics (1): Maximum A Posteriori - Taotao Tan</title><meta name="Description" content="Taotao&#39;s Blog Posts"><meta property="og:title" content="Dive into Bayesian statistics (1): Maximum A Posteriori" />
<meta property="og:description" content="I know, this is an exciting &amp; scary topic. It literally took me months to understand, and I hope this post will make your life easier.
Before you read this post, I assume you are already familiar with basic probability theories, maximum likelihood estimation and bayes theorem. I encourage you to read my previous post that discussed MLE, and we are going to use the same dataset in this post." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jasontan-code.github.io/posts/bayesian-1/" />
<meta property="og:image" content="https://jasontan-code.github.io/images/avatar.png"/>
<meta property="article:published_time" content="2021-11-22T17:18:26-06:00" />
<meta property="article:modified_time" content="2021-11-22T17:18:26-06:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jasontan-code.github.io/images/avatar.png"/>

<meta name="twitter:title" content="Dive into Bayesian statistics (1): Maximum A Posteriori"/>
<meta name="twitter:description" content="I know, this is an exciting &amp; scary topic. It literally took me months to understand, and I hope this post will make your life easier.
Before you read this post, I assume you are already familiar with basic probability theories, maximum likelihood estimation and bayes theorem. I encourage you to read my previous post that discussed MLE, and we are going to use the same dataset in this post."/>
<meta name="application-name" content="Taotao&#39;s Blog Posts">
<meta name="apple-mobile-web-app-title" content="Taotao&#39;s Blog Posts"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://jasontan-code.github.io/posts/bayesian-1/" /><link rel="prev" href="https://jasontan-code.github.io/posts/monte_corlo/" /><link rel="next" href="https://jasontan-code.github.io/posts/bayesian-2/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Dive into Bayesian statistics (1): Maximum A Posteriori",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/jasontan-code.github.io\/posts\/bayesian-1\/"
        },"genre": "posts","keywords": "Statistics","wordcount":  893 ,
        "url": "https:\/\/jasontan-code.github.io\/posts\/bayesian-1\/","datePublished": "2021-11-22T17:18:26-06:00","dateModified": "2021-11-22T17:18:26-06:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Taotao"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Taotao Tan">Taotao Tan</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Taotao Tan">Taotao Tan</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Dive into Bayesian statistics (1): Maximum A Posteriori</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Taotao</a></span>&nbsp;<span class="post-category">included in <a href="/categories/statistics/"><i class="far fa-folder fa-fw"></i>Statistics</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-22">2021-11-22</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;893 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-bayes-theorem">1. Bayes theorem</a>
      <ul>
        <li><a href="#frequentist-approach">Frequentist approach:</a></li>
        <li><a href="#bayesian-approach">Bayesian approach:</a></li>
      </ul>
    </li>
    <li><a href="#2-work-with-an-example">2. Work with an example</a></li>
    <li><a href="#appendix">Appendix</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>I know, this is an exciting &amp; scary topic. It literally took me months to understand, and I hope this post will make your life easier.</p>
<p>Before you read this post, I assume you are already familiar with basic probability theories, maximum likelihood estimation and bayes theorem. I encourage you to read my previous post that discussed <a href="https://jasontan-code.github.io/blog/mle/" target="_blank" rel="noopener noreffer">MLE</a>, and we are going to use the same dataset in this post.</p>
<p>Okay, let&rsquo;s get started.</p>
<p> <br>
 
 <br>
 </p>
<h2 id="1-bayes-theorem">1. Bayes theorem</h2>
<p>In inferential statistics, our goal is to <strong>infer the population parameters</strong>. That is, we observe the data, and from the data we guess the most likely population parameters. There are, in general, two ways to approach this.</p>
<blockquote>
<h3 id="frequentist-approach">Frequentist approach:</h3>
<p>A typical method applied by frequentist is maximum likelihood estimation, where we define the likelihood function as $P( \text{data} | \text{params})$. Our goal is to find a set of parameters that best fit our data.</p>
<p>In my previous <a href="https://jasontan-code.github.io/posts/mle/" target="_blank" rel="noopener noreffer">MLE</a> post, we observe the number of visitors (samples) per hour, and we are trying to estimate the population (estimate $\lambda$). From the data we have collected, the most likely $\lambda = 4.5$, which is a fixed number.</p>
</blockquote>
<blockquote>
<h3 id="bayesian-approach">Bayesian approach:</h3>
<p>Bayesian statisticians treat unknown parameters as a random variables. That means, the population parameter $\lambda$ could be any number. If we use the Bayesian framework to analyze the same problem above, we will end up with a <strong>probability distribution</strong> of $\lambda$, instead of a point estimate ($\lambda = 4.5$, in our case).</p>
<p>p.s. This is true in general, but in this post we are going to discuss Maximum A Posteriori, and this is an exception.</p>
</blockquote>
<p>Okay, that&rsquo;s enough dry words. Let&rsquo;s look at the math.</p>
<p>Bayes theorem states that:
$$
P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}
$$</p>
<p>This theorem was adapted to solve inferential statistics problems, where we have:
$$
P(\text{params} | \text{data}) = \frac{P(\text{data} | \text{params}) \cdot P(\text{params})}{P(\text{data})}
$$</p>
<p>Before we move forward, I want to clarify some terminologies:</p>
<blockquote>
<p>$P(\text{params} | \text{data})$<br>
Posterior distribution, This is what we are aiming to solve</p>
</blockquote>
<blockquote>
<p>$P(\text{data} | \text{params})$<br>
Likelihood function. We have already discussed the likelihood function <a href="https://jasontan-code.github.io/posts/mle/" target="_blank" rel="noopener noreffer">here</a>. Briefly, it means the the probability of observing the data, given a set of parameters.</p>
</blockquote>
<blockquote>
<p>$P(\text{params})$<br>
Prior distribution. We need to define this beforehand based on our prior knowledge. This is what makes Bayesian statistics powerful and controversial.</p>
</blockquote>
<blockquote>
<p>$P(\text{data})$<br>
A scaling factor, also called marginal likelihood. This quantity is to make sure that $\int_{- \infty}^{\infty} P(\text{params} | \text{data}) = 1$. Many times we can ignore it.</p>
</blockquote>
<p> <br>
 
 <br>
 </p>
<h2 id="2-work-with-an-example">2. Work with an example</h2>
<p>We will use the same dataset I used in <a href="https://jasontan-code.github.io/blog/mle/" target="_blank" rel="noopener noreffer">MLE</a>. Here is how it looks like:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Time</th>
<th style="text-align:right">Number of visitors</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">8:am - 9:am</td>
<td style="text-align:right">5</td>
</tr>
<tr>
<td style="text-align:left">9:am - 10:am</td>
<td style="text-align:right">3</td>
</tr>
<tr>
<td style="text-align:left">10:am - 11:am</td>
<td style="text-align:right">4</td>
</tr>
<tr>
<td style="text-align:left">11:am - 12:am</td>
<td style="text-align:right">6</td>
</tr>
</tbody>
</table>
<p>Again, we are going to model the data with a poisson distribution. But, we will add a prior distribution, since we are doing Bayesian inference.</p>
<p>Choosing prior distribution is somewhat subjective. Here I decided to use a <a href="https://en.wikipedia.org/wiki/Gamma_distribution" target="_blank" rel="noopener noreffer">gamma distribution</a> with $\alpha = 2, \beta = 2$.
$$
\lambda \sim Gamma (2, 2)
$$</p>
<p>Therefore, our Bayes formula becomes:
$$
P(\lambda | \text{data}) = \frac{\text{Poisson}( \text{data}| \lambda) \cdot  \text{Gamma(2,2)}}{P(\text{data})}
$$</p>
<p>For simplicity, I will skip the calculation here and only show you the result. But you can find all the steps in the appendix.</p>
<p>$$
P(\lambda | \text{data}) = c \cdot \lambda^{19} e^{- 6 \lambda} \quad \text{, where $c$ is a constant.}
$$</p>
<p> </p>
<p>The last step is try to find $\lambda_0$, so that $P(\lambda_0 | \text{data})$ reaches its maximum.</p>
<p>Again, I drew a picture to show you the shape of  $P(\lambda | \text{data})$</p>
<p><figure><a class="lightgallery" href="/images/Bayesian1/Bayesian1.png" title="bayesian1" data-thumbnail="/images/Bayesian1/Bayesian1.png" data-sub-html="<h2>Prior, likelihood function, and posterior</h2><p>bayesian1</p>">
        <img
            class="lazyload"
            src="/svg/loading.min.svg"
            data-src="/images/Bayesian1/Bayesian1.png"
            data-srcset="/images/Bayesian1/Bayesian1.png, /images/Bayesian1/Bayesian1.png 1.5x, /images/Bayesian1/Bayesian1.png 2x"
            data-sizes="auto"
            alt="/images/Bayesian1/Bayesian1.png" />
    </a><figcaption class="image-caption">Prior, likelihood function, and posterior</figcaption>
    </figure></p>
<p>Note: The prior and likelihood were rescaled for plotting.</p>
<p> </p>
<p>As you can see, the prior Gamma distribution has a peak when $\lambda \approx 0.5$. The likelihood reaches its peak when $\lambda = 4.5$. After combining prior and likelihood function, our posterior reaches its peak when $\lambda \approx 3.17$.</p>
<p> </p>
<p>This is why sometimes Bayesian inference is also called <strong>shrinkage method</strong>. Using MLE, we would have got our result $\lambda = 4.5$. But adding a prior distribution enforces $\lambda$ to shift toward the prior, and the posterior distribution eventually sits somewhere between the prior and the likelihood.</p>
<p> </p>
<p>That&rsquo;s the end of this blog. Thanks for reading!</p>
<p> <br>
 
 <br>
 
 <br>
 
 <br>
 </p>
<h2 id="appendix">Appendix</h2>
<h4 id="prior-distribution">Prior distribution</h4>
<p>Gamma distribution is defined as
$$
f(\lambda) = \frac{\beta^{\alpha}}{ (\alpha - 1)! } \cdot \lambda^{\alpha - 1} \cdot e^{- \beta \lambda}
$$</p>
<p>Plug $\alpha = 2, \beta = 2$, we get our prior distribution:</p>
<p>$$
f(\lambda) =4  \lambda \cdot e^{- 2 \lambda}
$$</p>
<p> <br>
 </p>
<h4 id="likelihood-function">Likelihood function</h4>
<p>We have already calculated the likelihood function <a href="https://jasontan-code.github.io/blog/mle/" target="_blank" rel="noopener noreffer">here</a>:</p>
<p>$$
P(\text{data} | \lambda) = \frac{\lambda^5 e^{- \lambda}}{5 !} \times \frac{\lambda^3 e^{- \lambda}}{3 !} \times \frac{\lambda^4 e^{- \lambda}}{4 !} \times \frac{\lambda^6 e^{- \lambda}}{6 !}
$$</p>
<p> <br>
 </p>
<h4 id="combine-prior-and-likelihood">Combine prior and likelihood</h4>
<p>$$
\begin{aligned} P(\text{data} | \lambda) \cdot P(\lambda) &amp;=\frac{\lambda^5 e^{- \lambda}}{5 !} \times \frac{\lambda^3 e^{- \lambda}}{3 !} \times \frac{\lambda^4 e^{- \lambda}}{4 !} \times \frac{\lambda^6 e^{- \lambda}}{6 !} \times  4  \lambda \cdot e^{- 2 \lambda}  \\
&amp;= \frac{4}{5! \cdot 3! \cdot 4! \cdot 6! } \cdot \lambda^{19} e^{- 6 \lambda} \end{aligned}
$$</p>
<p>As I mentioned before, the denominator of the equation is a scaling factor/constant, therefore we can write our posterior probability as:</p>
<p>$$
P(\lambda | \text{data}) = c \cdot \lambda^{19} e^{- 6 \lambda}
$$</p>
<p> <br>
 
 <br>
 
 <br>
 
 <br>
 </p>
<h2 id="reference">Reference</h2>
<p>Wiki-Conjugate_prior : <a href="https://en.wikipedia.org/wiki/Conjugate_prior">https://en.wikipedia.org/wiki/Conjugate_prior</a></p>
<p>Wiki-Gamma_distribution: <a href="https://en.wikipedia.org/wiki/Gamma_distribution">https://en.wikipedia.org/wiki/Gamma_distribution</a></p>
<p>Wiki-Poisson_distribution: <a href="https://en.wikipedia.org/wiki/Poisson_distribution">https://en.wikipedia.org/wiki/Poisson_distribution</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-22</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori" data-via="doubleTaoTan" data-hashtags="Statistics"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-hashtag="Statistics"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Myspace" data-sharer="myspace" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori" data-description=""><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori" data-description=""><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="https://jasontan-code.github.io/posts/bayesian-1/" data-title="Dive into Bayesian statistics (1): Maximum A Posteriori"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/statistics/">Statistics</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/monte_corlo/" class="prev" rel="prev" title="How to draw sample from a generic distribution?"><i class="fas fa-angle-left fa-fw"></i>How to draw sample from a generic distribution?</a>
            <a href="/posts/bayesian-2/" class="next" rel="next" title="Dive into Bayesian statistics (2): Solve the nasty denominator!">Dive into Bayesian statistics (2): Solve the nasty denominator!<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="fb-root" class="comment"></div>
            <div
                class="fb-comments"
                data-href="https://jasontan-code.github.io/posts/bayesian-1/"
                data-width="100%"
                data-numposts="10"
            ></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://developers.facebook.com/docs/plugins/comments/"></a>Facebook</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.80.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v5.0&amp;appId=2162149760591137&amp;autoLogAppEvents=1" defer></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-C4MZRQHWVE', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=G-C4MZRQHWVE" async></script></body>
</html>
