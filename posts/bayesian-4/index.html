<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Dive into Bayesian statistics (4): Posterior predictive distribution - Taotao Tan</title><meta name="Description" content="Taotao&#39;s Blog Posts"><meta property="og:title" content="Dive into Bayesian statistics (4): Posterior predictive distribution" />
<meta property="og:description" content="In the last few posts, we tried three methods (Integration, Conjugate Prior and MCMC) to infer the posterior distribution $P(\lambda | \text{data})$, which gave us
$$\lambda \sim \text{Gamma}(\alpha = 20, \beta = 6)$$
Now you may ask: Cool, we have our posterior distribution, but SO WHAT?
In this post, we are going to see why studying the posterior distribution is advantageous and interesting, and show you the internal relationship between a Poisson distribution, a Gamma distribution and a Negative binomial distribution." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jasontan-code.github.io/posts/bayesian-4/" />
<meta property="og:image" content="https://jasontan-code.github.io/images/avatar.png"/>
<meta property="article:published_time" content="2021-11-22T20:18:26-06:00" />
<meta property="article:modified_time" content="2021-11-22T20:18:26-06:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jasontan-code.github.io/images/avatar.png"/>

<meta name="twitter:title" content="Dive into Bayesian statistics (4): Posterior predictive distribution"/>
<meta name="twitter:description" content="In the last few posts, we tried three methods (Integration, Conjugate Prior and MCMC) to infer the posterior distribution $P(\lambda | \text{data})$, which gave us
$$\lambda \sim \text{Gamma}(\alpha = 20, \beta = 6)$$
Now you may ask: Cool, we have our posterior distribution, but SO WHAT?
In this post, we are going to see why studying the posterior distribution is advantageous and interesting, and show you the internal relationship between a Poisson distribution, a Gamma distribution and a Negative binomial distribution."/>
<meta name="application-name" content="Taotao&#39;s Blog Posts">
<meta name="apple-mobile-web-app-title" content="Taotao&#39;s Blog Posts"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://jasontan-code.github.io/posts/bayesian-4/" /><link rel="prev" href="https://jasontan-code.github.io/posts/bayesian-3/" /><link rel="next" href="https://jasontan-code.github.io/posts/bayesian-5/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Dive into Bayesian statistics (4): Posterior predictive distribution",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/jasontan-code.github.io\/posts\/bayesian-4\/"
        },"genre": "posts","keywords": "Statistics","wordcount":  776 ,
        "url": "https:\/\/jasontan-code.github.io\/posts\/bayesian-4\/","datePublished": "2021-11-22T20:18:26-06:00","dateModified": "2021-11-22T20:18:26-06:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Taotao"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Taotao Tan">Taotao Tan</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Taotao Tan">Taotao Tan</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Dive into Bayesian statistics (4): Posterior predictive distribution</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Taotao</a></span>&nbsp;<span class="post-category">included in <a href="/categories/statistics/"><i class="far fa-folder fa-fw"></i>Statistics</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-22">2021-11-22</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;776 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;4 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#question">Question:</a></li>
    <li><a href="#a-frequentist-framework">A Frequentist Framework:</a></li>
    <li><a href="#a-bayesian-framework">A Bayesian Framework:</a></li>
    <li><a href="#sampling-of-posterior-predictive">Sampling of posterior predictive</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#summary">Summary:</a></li>
    <li><a href="#reference">Reference:</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>In the last few posts, we tried three methods (<a href="https://jasontan-code.github.io/posts/bayesian-2/" target="_blank" rel="noopener noreffer">Integration, Conjugate Prior</a> and <a href="https://jasontan-code.github.io/posts/bayesian-3/" target="_blank" rel="noopener noreffer">MCMC</a>) to infer the posterior distribution $P(\lambda | \text{data})$, which gave us</p>
<p>$$\lambda \sim \text{Gamma}(\alpha = 20, \beta = 6)$$</p>
<p>Now you may ask: Cool, we have our posterior distribution, but SO WHAT?</p>
<p>In this post, we are going to see why studying the posterior distribution is advantageous and interesting, and show you the internal relationship between a Poisson distribution, a Gamma distribution and a Negative binomial distribution.</p>
<p> <br>
 
 </p>
<h2 id="question">Question:</h2>
<p>Here is the data we have worked so far:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Time</th>
<th style="text-align:right">Number of visitors</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">8:am - 9:am</td>
<td style="text-align:right">5</td>
</tr>
<tr>
<td style="text-align:left">9:am - 10:am</td>
<td style="text-align:right">3</td>
</tr>
<tr>
<td style="text-align:left">10:am - 11:am</td>
<td style="text-align:right">4</td>
</tr>
<tr>
<td style="text-align:left">11:am - 12:pm</td>
<td style="text-align:right">6</td>
</tr>
</tbody>
</table>
<p>In this post, we will try to answer a question:  <strong>What is the probability that my website has no visitors in the next hour?</strong></p>
<p>The question might look a little strange at the first glance. How am I supposed to know the number of visitors in the future? In this post, we are going to address this question in two different manners: <strong>a frequentist framework</strong>, and <strong>a Bayesian framework</strong></p>
<p> <br>
 <br>
 
 </p>
<h2 id="a-frequentist-framework">A Frequentist Framework:</h2>
<p>As what I have discussed in <a href="https://jasontan-code.github.io/blog/mle/" target="_blank" rel="noopener noreffer">this post</a>, we assumed that the data has a Poisson distribution, and used Maximum Likelihood Estimation to figure out the most likely $\lambda = 4.5$. Now, we can simply plug $\lambda = 4.5$ into the Poisson distribution formula, which becomes our inferred population now:
$$
f(x) = \frac{4.5^x e^{-4.5}}{x!}
$$</p>
<p>To answer the question above, we simply plug in $x = 0$, and get:
$$
f(0) = \frac{4.5^0 e^{-4.5}}{0!} = 0.011
$$</p>
<p>So, under a frequentist framework, our answer is 0.011</p>
<p> <br>
 <br>
 
 </p>
<h2 id="a-bayesian-framework">A Bayesian Framework:</h2>
<p>Now let&rsquo;s try to answer the question using a Bayesian framework. We have already derived the posterior distribution:</p>
<p>$$\lambda \sim \text{Gamma}(\alpha = 20, \beta = 6)$$</p>
<p>Then we also have the distribution of the data:</p>
<p>$$x \sim \text{Poisson}(\lambda)$$</p>
<p>Let&rsquo;s try to concatenate the gamma distribution (which is the pdf of $\lambda$), and the poisson distribution (which is the pdf of data). This should gives us the <strong>probability distribution of the predictive data</strong>.</p>
<p>$$
\begin{aligned}
f(x; \alpha = 20, \beta = 6) &amp; = \int_0^{+ \infty} \frac{\lambda^x e^{-\lambda}}{x!} \cdot \frac{6^{20}}{19!} \lambda^{19} e^{-6\lambda} \cdot d\lambda \\
&amp; = \frac{6^{20}}{19! \cdot x!} \int_{0}^{+\infty} \lambda^{19 + x} e^{-7 \lambda} d\lambda \\
&amp; \stackrel{\dagger}{=} \frac{6^{20}}{19! \cdot x!}  \cdot \frac{\Gamma{(20 + x)}}{7^{20 + x}} \\
&amp; = \frac{\Gamma (20 + x)}{19 ! \cdot x!} \cdot (\frac{6}{7})^{20} \cdot (\frac{1}{7})^x \\
&amp; = \frac{\Gamma (20 + x)}{\Gamma (20) \cdot \Gamma (x + 1)} \cdot (\frac{6}{7})^{20} \cdot (\frac{1}{7})^x \\
&amp; =  {x + 19 \choose x}\cdot (\frac{6}{7})^{20} \cdot (\frac{1}{7})^x
\end{aligned}
$$</p>
<p>Note: step $\dagger$ holds because
$$
\int_0^{+\infty} x^a e^{-bx} dx = \frac{ \Gamma(a + 1)}{b ^{a + 1}} \text{      ,where } a, b \text{ are integers}
$$</p>
<p><strong>Therefore, we can make the conclusion that the posterior predictive distribution has a negative binomial distribution with $p = 6/7, r = 20$</strong></p>
<p>From the posterior predictive distribution, we can easily calculate the probability of having no visitors in the next hour:</p>
<p>$$
f(0) = {19 \choose 0}\cdot (\frac{6}{7})^{20} \cdot (\frac{1}{7})^0 = 0.046
$$</p>
<p> 
 <br>
 
 <br>
 </p>
<h2 id="sampling-of-posterior-predictive">Sampling of posterior predictive</h2>
<p>Lastly, let&rsquo;s do a little bit of sampling to verify our result. Again, there are two ways:
 <br>
 </p>
<h4 id="method-1">Method 1:</h4>
<p>Draw $\lambda$ from a gamma distribution, then use this lambda in a Poisson distribution:</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="n">bag1</span> <span class="o">=</span> <span class="nf">c</span><span class="p">()</span>

<span class="nf">for </span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="m">100000</span><span class="p">){</span>
  <span class="n">lambda</span> <span class="o">=</span> <span class="nf">rgamma</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="m">20</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="m">6</span><span class="p">)</span>
  <span class="n">bag1[i]</span> <span class="o">=</span> <span class="nf">rpois</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">lambda</span> <span class="o">=</span> <span class="n">lambda</span><span class="p">)</span>
<span class="p">}</span>
<span class="c1"># draw a histogram</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bag1</span><span class="p">),</span> <span class="nf">aes</span><span class="p">(</span><span class="n">bag1</span><span class="p">))</span> <span class="o">+</span> <span class="nf">geom_bar</span><span class="p">()</span>
</code></pre></div><p>This gave us:</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/Bayesian4/bag1.png"
        data-srcset="/images/Bayesian4/bag1.png, /images/Bayesian4/bag1.png 1.5x, /images/Bayesian4/bag1.png 2x"
        data-sizes="auto"
        alt="/images/Bayesian4/bag1.png"
        title="bayesian4" /></p>
<p> 
 </p>
<h4 id="method-2">Method 2:</h4>
<p>Draw samples from the negative binomial distribution directly:</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="n">bag2</span> <span class="o">=</span> <span class="nf">rnbinom</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="m">100000</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="m">20</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="m">6</span><span class="o">/</span><span class="m">7</span><span class="p">)</span>
<span class="c1"># draw a histogram</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bag2</span><span class="p">),</span> <span class="nf">aes</span><span class="p">(</span><span class="n">bag2</span><span class="p">))</span> <span class="o">+</span> <span class="nf">geom_bar</span><span class="p">()</span>
</code></pre></div><p>This gave us:</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/Bayesian4/bag2.png"
        data-srcset="/images/Bayesian4/bag2.png, /images/Bayesian4/bag2.png 1.5x, /images/Bayesian4/bag2.png 2x"
        data-sizes="auto"
        alt="/images/Bayesian4/bag2.png"
        title="bayesian4" /></p>
<p>,which is almost identical as method 1</p>
<p> 
 <br>
 
 <br>
 
 </p>
<h2 id="summary">Summary:</h2>
<p>In this post, we saw two completely different frameworks of inferring the data.</p>
<p> 
 </p>
<p>The frequentist approach assumes the <strong>parameters are fixed</strong> and <strong>data are random</strong>, and we use MLE to estimate the most likely parameters. Here is how it works:</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/Bayesian4/freq.png"
        data-srcset="/images/Bayesian4/freq.png, /images/Bayesian4/freq.png 1.5x, /images/Bayesian4/freq.png 2x"
        data-sizes="auto"
        alt="/images/Bayesian4/freq.png"
        title="bayesian4" /></p>
<p> 
 <br>
 </p>
<p>Whereas under the Bayesian framework, not only the <strong>data are random</strong>, but the <strong>parameters are also random</strong>. By adding a prior distribution, we can infer a parameter distribution. To generate data, we will first draw random parameters, and from those random parameters, we then draw random data. Here is a graphic demonstration:</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/Bayesian4/bayesian.png"
        data-srcset="/images/Bayesian4/bayesian.png, /images/Bayesian4/bayesian.png 1.5x, /images/Bayesian4/bayesian.png 2x"
        data-sizes="auto"
        alt="/images/Bayesian4/bayesian.png"
        title="bayesian4" /></p>
<p> 
 <br>
 </p>
<p>Besides all that, we also learned that the concatenation of a Gamma distribution and a Poisson distribution is a Negative Binomial distribution.</p>
<p> <br>
 </p>
<p>Thanks for reading this post. If like the content, don&rsquo;t hesitate to leave comments and drop a thumb up.</p>
<p> <br>
 
 <br>
 <br>
 
 <br>
 
 </p>
<h2 id="reference">Reference:</h2>
<p>Angina Seng @ Stack Exchange: <a href="https://math.stackexchange.com/a/3407923/938478">https://math.stackexchange.com/a/3407923/938478</a></p>
<p>Wiki Negative binomial: <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution#Gamma%E2%80%93Poisson_mixture">https://en.wikipedia.org/wiki/Negative_binomial_distribution#Gamma%E2%80%93Poisson_mixture</a></p>
<p>Wiki Conjugate prior: <a href="https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions">https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-22</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution" data-via="doubleTaoTan" data-hashtags="Statistics"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-hashtag="Statistics"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Myspace" data-sharer="myspace" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution" data-description=""><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution" data-description=""><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="https://jasontan-code.github.io/posts/bayesian-4/" data-title="Dive into Bayesian statistics (4): Posterior predictive distribution"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/statistics/">Statistics</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/bayesian-3/" class="prev" rel="prev" title="Dive into Bayesian statistics (3): Markov Chain Monte Carlo"><i class="fas fa-angle-left fa-fw"></i>Dive into Bayesian statistics (3): Markov Chain Monte Carlo</a>
            <a href="/posts/bayesian-5/" class="next" rel="next" title="Dive into Bayesian statistics (5): Intro to PyMC3">Dive into Bayesian statistics (5): Intro to PyMC3<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="fb-root" class="comment"></div>
            <div
                class="fb-comments"
                data-href="https://jasontan-code.github.io/posts/bayesian-4/"
                data-width="100%"
                data-numposts="10"
            ></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://developers.facebook.com/docs/plugins/comments/"></a>Facebook</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.80.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v5.0&amp;appId=2162149760591137&amp;autoLogAppEvents=1" defer></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-C4MZRQHWVE', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=G-C4MZRQHWVE" async></script></body>
</html>
